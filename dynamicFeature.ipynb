{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Dynamic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessingNA as pp\n",
    "import data2D3D\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import logging\n",
    "import nibabel as nib\n",
    "import gc\n",
    "from skimage import transform\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import tensorflow as tf\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import pickle\n",
    "import sys\n",
    "%matplotlib inline\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "from torch.utils import data as D\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from time import time\n",
    "from data2D3D import data2D3D\n",
    "from D_UNet import U_Net\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_image(image):\n",
    "    '''\n",
    "    make image zero mean and unit standard deviation\n",
    "    '''\n",
    "\n",
    "    img_o = np.float32(image.copy())\n",
    "    m = np.mean(img_o)\n",
    "    s = np.std(img_o)\n",
    "    return np.divide((img_o - m), s)\n",
    "\n",
    "\n",
    "\n",
    "def crop_or_pad_slice_to_size(slice, nx=224, ny=224):\n",
    "\n",
    "    x, y = slice.shape\n",
    "\n",
    "    x_s = (x - nx) // 2\n",
    "    y_s = (y - ny) // 2\n",
    "    x_c = (nx - x) // 2\n",
    "    y_c = (ny - y) // 2\n",
    "\n",
    "    if x > nx and y > ny:\n",
    "        slice_cropped = slice[x_s:x_s + nx, y_s:y_s + ny]\n",
    "    else:\n",
    "        slice_cropped = np.zeros((nx, ny))\n",
    "        if x <= nx and y > ny:\n",
    "            slice_cropped[x_c:x_c + x, :] = slice[:, y_s:y_s + ny]\n",
    "        elif x > nx and y <= ny:\n",
    "            slice_cropped[:, y_c:y_c + y] = slice[x_s:x_s + nx, :]\n",
    "        else:\n",
    "            slice_cropped[x_c:x_c + x, y_c:y_c + y] = slice[:, :]\n",
    "\n",
    "    return slice_cropped\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4D_image folders include all subjects' 4D images\n",
    "##### Each subject created their own folders saved into 4D_image folder\n",
    "##### In each subjects' folder, 3D images were created for each time steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "def data_prepare4D (nx=224, norm=True, test=False, numS=1):\n",
    "    num=0\n",
    "    imageS=[]\n",
    "    img_T=[]\n",
    "    imageSS=[]\n",
    "    filename3D=[]\n",
    "    imgC=glob.glob(os.path.join('datacollect', 'patient???_frame??.nii.gz'))\n",
    "    path='4D_image/patient'+'{:03d}'.format(numS)\n",
    "    imgC=glob.glob(os.path.join(path, 'slice??.nii')) \n",
    "    imgC.sort()\n",
    "    \n",
    "    file_count = len(fnmatch.filter(os.listdir('4D_image/patient'+'{:03d}'.format(numS)), '*.nii'))\n",
    "    stack=0\n",
    "\n",
    "    for i in range(file_count):\n",
    "        \n",
    "        image_name=imgC[i]\n",
    "        imageTemperate=nib.load(image_name).get_fdata()\n",
    "        image=np.zeros((imageTemperate.shape[0],imageTemperate.shape[1],imageTemperate.shape[2]+2))\n",
    "        image[:,:,1:-1]=imageTemperate\n",
    "        image[:,:,0]=imageTemperate[:,:,0]\n",
    "        image[:,:,-1]=imageTemperate[:,:,-1]\n",
    "        \n",
    "        imageS.append(image.shape[-1])\n",
    "        #num=num+imageS[i]    \n",
    "    \n",
    "        target_resolution = (1.37, 1.37)      \n",
    "        img = image\n",
    "        img = normalise_image(img)\n",
    "    \n",
    "        n1_header = nib.load(image_name).header\n",
    "        pixel_size=n1_header['pixdim'][1:3] \n",
    "        scale_vector = [pixel_size[0] / target_resolution[0], pixel_size[1] / target_resolution[1]]\n",
    "\n",
    "        \n",
    "        for zz in range(img.shape[2]):\n",
    "\n",
    "            slice_img = np.squeeze(img[:, :, zz])\n",
    "            slice_rescaled = transform.rescale(slice_img,scale_vector, order=1, \n",
    "                                               preserve_range=True,multichannel=False,mode = 'constant')\n",
    "\n",
    "            slice_cropped = crop_or_pad_slice_to_size(slice_rescaled, nx, nx)\n",
    "            img_T.append(slice_cropped)\n",
    "  \n",
    "            if zz!=0 and zz!=img.shape[2]-1:\n",
    "                imageSS.append(stack)\n",
    "                filename3D.append(image_name)\n",
    "       \n",
    "            stack=stack+1\n",
    "    \n",
    "    img_T=np.float32(np.array(img_T));    \n",
    "\n",
    "\n",
    "    num=img_T.shape[0]    \n",
    "    return img_T, imageSS, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect4DMask(testloader, test_indices, test_tumor_dataset, numS, file_count):\n",
    "    # load model\n",
    "    unet_model = U_Net().to(device)\n",
    "    checkpoint = torch.load('./saved_models/WCE/Basic_Unet_epoch_066.pth',map_location=torch.device('cpu'))\n",
    "    unet_model.load_state_dict(checkpoint)\n",
    "    # Testing process on test data.\n",
    "    unet_model.eval()\n",
    "    \n",
    "    \n",
    "    Maskvolume = np.zeros((nx,nx,file_count))\n",
    "    fileIndex=1\n",
    "    directory='4D_mask/patient'+'{:03d}'.format(numS)\n",
    "    os.mkdir(directory)\n",
    "    \n",
    "    for example_index, data in enumerate(testloader):\n",
    "        #print(example_index)\n",
    "        image2D = data['image2D'].numpy()#.to(device)\n",
    "        image3D = data['image3D'].numpy()#.to(device)        \n",
    "        unet_model.eval()  \n",
    "        image_tensor2D = torch.Tensor(image2D)\n",
    "        image_tensor2D = image_tensor2D.view((1, 3, nx, nx)).to(device)\n",
    "        image_tensor3D = torch.Tensor(image3D)\n",
    "        image_tensor3D = image_tensor3D.view((1, 1, 3, nx, nx)).to(device)  \n",
    "        output = unet_model(image_tensor2D, image_tensor3D).detach().cpu()\n",
    "        output=F.softmax(output, dim=1)\n",
    "        output = torch.max(output, 1)[1]\n",
    "        output = output.numpy()\n",
    "        output = np.resize(output, (nx, nx))\n",
    "        Maskvolume[:,:,example_index%file_count]=output\n",
    "    \n",
    "        if (example_index+1)%file_count==0:\n",
    "            img = nib.nifti1.Nifti1Image(Maskvolume, np.eye(4))\n",
    "            img.get_data_dtype() == np.dtype(np.int16)\n",
    "            file_name='slice'+'{:02d}'.format(fileIndex)\n",
    "            img.to_filename(os.path.join(directory,file_name))\n",
    "            fileIndex=fileIndex+1\n",
    "            Maskvolume = np.zeros((nx,nx,file_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [18:48<00:00, 376.14s/it]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1,101)):\n",
    "    path = '4D_image/patient' +'{:03d}'.format(i)\n",
    "    nx=224;\n",
    "    Test_img_T, Test_imageSS, Test_num=data_prepare4D(nx=224, norm=False, test=True, numS=i)\n",
    "    test_tumor_dataset = data2D3D(path, Test_imageSS, Test_img_T, Test_img_T, Test_num, nx, aug=True)\n",
    "    #test_indices=list(range(0,Test_num-2*file_count))\n",
    "\n",
    "    #path, dirs, files = next(os.walk(path))\n",
    "    file_count = len(glob.glob(os.path.join(path, 'slice??.nii'))) #len(files)\n",
    "    number=np.int((Test_num-2*file_count))\n",
    "    test_indices=list(range(0,number))\n",
    "\n",
    "    test_sampler=torch.utils.data.SequentialSampler(test_indices)\n",
    "    testloader = torch.utils.data.DataLoader(test_tumor_dataset, 1,num_workers=0, sampler=test_sampler, shuffle=False )\n",
    "\n",
    "    image_name=glob.glob(os.path.join(path, 'slice01.nii')) \n",
    "    thickness=nib.load(image_name[0]).get_fdata().shape[-1]\n",
    "    collect4DMask(testloader=testloader, test_indices=test_indices, test_tumor_dataset=test_tumor_dataset, numS=i, file_count=thickness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size =5> Collect Dynamic Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis\n",
    "from scipy.stats import skew \n",
    "\n",
    "def dynamicFeature(file_count,numS,xResolution,yResolution,zResolution):\n",
    "    TResolution=xResolution*yResolution*zResolution\n",
    "    LVCvolume = []\n",
    "    RVCvolume = []\n",
    "    Myovolume = []\n",
    "    for fileIndex in range(file_count):\n",
    "        directory='4D_mask/patient'+'{:03d}'.format(numS)\n",
    "        file_name=directory+'/slice'+'{:02d}'.format(fileIndex+1) +'.nii'\n",
    "        image=nib.load(file_name).get_fdata()\n",
    "        image1=image.copy()\n",
    "        image1[(image1!=1)]=0\n",
    "        image1[(image1==1)]=1\n",
    "        #image1Agg=image1.sum(axis=2)*zResolution\n",
    "        RVCvolume.append(TResolution*image1.sum(axis=0).sum(axis=0).sum(axis=0))\n",
    "\n",
    "        image2=image.copy()\n",
    "        image2[(image2!=2)]=0\n",
    "        image2[(image2==2)]=1\n",
    "        Myovolume.append(TResolution*image2.sum(axis=0).sum(axis=0).sum(axis=0))\n",
    "        #image2Agg=image2.sum(axis=2)\n",
    "        #IMG2AGG=(mask*image2).sum(axis=2)*zResolution\n",
    "\n",
    "        image3=image.copy()\n",
    "        image3[(image!=3)]=0\n",
    "        image3[(image3==3)]=1\n",
    "        LVCvolume.append(TResolution*image3.sum(axis=0).sum(axis=0).sum(axis=0))\n",
    "        #image3Agg=image3.sum(axis=2)*zResolution\n",
    "    RVCvolume=np.asarray((RVCvolume))\n",
    "    Myovolume=np.asarray((Myovolume))\n",
    "    LVCvolume=np.asarray((LVCvolume))\n",
    "    vMaxRVC=np.max(RVCvolume)\n",
    "    vMaxMyo=np.max(Myovolume)\n",
    "    vMaxLVC=np.max(LVCvolume)\n",
    "    vMinRVC=np.min(RVCvolume)\n",
    "    vMinMyo=np.min(Myovolume)\n",
    "    vMinLVC=np.min(LVCvolume)\n",
    "    vMedRVC=np.median(RVCvolume)\n",
    "    vMedMyo=np.median(Myovolume)\n",
    "    vMedLVC=np.median(LVCvolume)\n",
    "    vkurtosisRVC=kurtosis(RVCvolume)\n",
    "    vkurtosisMyo=kurtosis(Myovolume)\n",
    "    vkurtosisLVC=kurtosis(LVCvolume)\n",
    "    vskewRVC=skew(RVCvolume)\n",
    "    vskewMyo=skew(Myovolume)\n",
    "    vskewLVC=skew(LVCvolume)\n",
    "    vstdRVC=np.std(RVCvolume)\n",
    "    vstdMyo=np.std(Myovolume)\n",
    "    vstdLVC=np.std(LVCvolume)\n",
    "    vminLVC_vminRVC=vMinLVC/vMinRVC\n",
    "    vminLVM_vminLVC=vMinMyo/vMinLVC\n",
    "    vminRVC_vminLVM=vMinRVC/vMinMyo\n",
    "\n",
    "#time step difference t(vmin,LVC)-t(vmin,RVC) time step difference t(vmax,LVC)-t(vmax,RVC)\n",
    "\n",
    "\n",
    "    return  vMaxRVC,vMaxMyo,vMaxLVC,vMinRVC,vMinMyo,vMinLVC,vMedRVC,vMedMyo,vMedLVC,\\\n",
    "    vkurtosisRVC,vkurtosisMyo,vkurtosisLVC,vskewRVC,vskewMyo,vskewLVC,vstdRVC,vstdMyo,vstdLVC,\\\n",
    "    vminLVC_vminRVC,vminLVM_vminLVC,vminRVC_vminLVM\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:35<00:00,  2.16s/it]\n"
     ]
    }
   ],
   "source": [
    "vMaxRVC,vMaxMyo,vMaxLVC,vMinRVC,vMinMyo,vMinLVC,vMedRVC,vMedMyo,vMedLVC,\\\n",
    "vkurtosisRVC,vkurtosisMyo,vkurtosisLVC,vskewRVC,vskewMyo,vskewLVC,vstdRVC,vstdMyo,vstdLVC,\\\n",
    "vminLVC_vminRVC,vminLVM_vminLVC,vminRVC_vminLVM = [[] for i in range(21)]\n",
    "for i in  tqdm(range(1,101)):\n",
    "    image_name='4D_image/patient' +'{:03d}'.format(i)+'/slice01.nii'\n",
    "    xResolution= 1.37 #nib.load(image_name).header['pixdim'][1]\n",
    "    yResolution= 1.37 #nib.load(image_name).header['pixdim'][2]\n",
    "    zResolution=nib.load(image_name).header['pixdim'][3]\n",
    "    TResolution=xResolution*yResolution*zResolution\n",
    "    path='4D_mask/patient' +'{:03d}'.format(i)\n",
    "    file_count = len(glob.glob(os.path.join(path, 'slice??.nii')))\n",
    "    VMaxRVC,VMaxMyo,VMaxLVC,VMinRVC,VMinMyo,VMinLVC,VMedRVC,VMedMyo,VMedLVC,\\\n",
    "    VkurtosisRVC,VkurtosisMyo,VkurtosisLVC,VskewRVC,VskewMyo,VskewLVC,VstdRVC,VstdMyo,VstdLVC,\\\n",
    "    VminLVC_vminRVC,VminLVM_vminLVC,VminRVC_vminLVM=dynamicFeature(file_count,i,xResolution,yResolution,zResolution)\n",
    "    \n",
    "    vMaxRVC.append(VMaxRVC)\n",
    "    vMaxMyo.append(VMaxMyo)\n",
    "    vMaxLVC.append(VMaxLVC)\n",
    "    vMinRVC.append(VMinRVC)\n",
    "    vMinMyo.append(VMinMyo)\n",
    "    vMinLVC.append(VMinLVC)\n",
    "    vMedRVC.append(VMedRVC)\n",
    "    vMedMyo.append(VMedMyo)\n",
    "    vMedLVC.append(VMedLVC)\n",
    "    vkurtosisRVC.append(VkurtosisRVC)\n",
    "    vkurtosisMyo.append(VkurtosisMyo)\n",
    "    vkurtosisLVC.append(VkurtosisLVC)\n",
    "    vskewRVC.append(VskewRVC)\n",
    "    vskewMyo.append(VskewMyo)\n",
    "    vskewLVC.append(VskewLVC)\n",
    "    vstdRVC.append(VstdRVC)\n",
    "    vstdMyo.append(VstdMyo)\n",
    "    vstdLVC.append(VstdLVC)\n",
    "    vminLVC_vminRVC.append(VminLVC_vminRVC)\n",
    "    vminLVM_vminLVC.append(VminLVM_vminLVC)\n",
    "    vminRVC_vminLVM.append(VminRVC_vminLVM)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<font size =5> Merge the dynamic features with the instant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('featureRecords.csv')\n",
    "y[\"Group\"]=dataset[\"Group\"]\n",
    "dataset.drop([\"Group\"],axis=1, inplace=True)\n",
    "dataset[\"vMaxRVC\"]=vMaxRVC\n",
    "dataset[\"vMaxMyo\"]=vMaxMyo\n",
    "dataset[\"vMaxLVC\"]=vMaxLVC\n",
    "dataset[\"vMinRVC\"]=vMinRVC\n",
    "dataset[\"vMinMyo\"]=vMinMyo\n",
    "dataset[\"vMinLVC\"]=vMinLVC\n",
    "dataset[\"vMedRVC\"]=vMedRVC\n",
    "dataset[\"vMedMyo\"]=vMedMyo\n",
    "dataset[\"vMedLVC\"]=vMedLVC\n",
    "dataset[\"vkurtosisRVC\"]=vkurtosisRVC\n",
    "dataset[\"vkurtosisMyo\"]=vkurtosisMyo\n",
    "dataset[\"vkurtosisLVC\"]=vkurtosisLVC\n",
    "dataset[\"vskewRVC\"]=vskewRVC\n",
    "dataset[\"vskewMyo\"]=vskewMyo\n",
    "dataset[\"vskewLVC\"]=vskewLVC\n",
    "dataset[\"vstdRVC\"]=vstdRVC\n",
    "dataset[\"vstdMyo\"]=vstdMyo\n",
    "dataset[\"vstdLVC\"]=vstdLVC\n",
    "dataset[\"vminLVC_vminRVC\"]=vminLVC_vminRVC\n",
    "dataset[\"vminLVM_vminLVC\"]=vminLVM_vminLVC\n",
    "dataset[\"vminRVC_vminLVM\"]=vminRVC_vminLVM\n",
    "dataset[\"Group\"]=y[\"Group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"allFeatures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
